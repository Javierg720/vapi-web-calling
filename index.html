<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VAPI Web Calling - Live Voice Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .form-group {
            margin-bottom: 20px;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
            color: #555;
        }
        input, textarea, select {
            width: 100%;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
            box-sizing: border-box;
        }
        textarea {
            height: 150px;
            resize: vertical;
        }
        button {
            background-color: #007bff;
            color: white;
            padding: 12px 24px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            margin-right: 10px;
        }
        button:hover {
            background-color: #0056b3;
        }
        .response-area {
            margin-top: 30px;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border: 1px solid #e9ecef;
        }
        .success {
            color: #28a745;
        }
        .error {
            color: #dc3545;
        }
        .loading {
            color: #ffc107;
        }
        .preset-buttons {
            margin-bottom: 20px;
        }
        .preset-buttons button {
            background-color: #6c757d;
            margin-right: 5px;
            margin-bottom: 5px;
            padding: 8px 16px;
            font-size: 14px;
        }
        .preset-buttons button:hover {
            background-color: #545b62;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üåê VAPI Web Calling</h1>
        <p style="text-align: center; color: #666;">Live Voice Assistant with 3D Orb Interface</p>
        
        <!-- Quick Access -->
        <div style="text-align: center; margin-bottom: 30px;">
            <button onclick="showVoiceTestPanel()" style="background-color: #17a2b8; font-size: 18px; padding: 15px 30px;">üåê Start Voice Assistant</button>
        </div>

        <!-- Hidden API testing form - keeping for backend compatibility -->
        <form id="vapiForm" style="display: none;">
            <input type="hidden" id="apiKey" value="445a1e08-666d-47ea-abdd-cc0ac09d23bc">
        </form>

        <div id="voiceTestPanel" class="response-area" style="display: none;">
            <h3>üåê AI Voice Assistant Orb</h3>
            <p style="text-align: center; color: #666; margin-bottom: 20px;">Real-time streaming conversation with animated 3D orb</p>
            
            <div class="form-group">
                <label for="voiceProvider">Voice Provider:</label>
                <select id="voiceProvider" onchange="updateVoiceOptions()">
                    <option value="kokoro">Kokoro TTS</option>
                    <option value="edge">Edge TTS</option>
                </select>
            </div>
            <div class="form-group">
                <label for="voiceSelect">Voice:</label>
                <select id="voiceSelect">
                    <option value="af_heart">Kokoro - af_heart</option>
                </select>
            </div>

            <!-- 3D Orb Container -->
            <div id="orbContainer" style="width: 100%; height: 300px; background: linear-gradient(135deg, #1e3c72, #2a5298); border-radius: 15px; position: relative; overflow: hidden; margin: 20px 0;">
                <canvas id="orbCanvas" style="width: 100%; height: 100%;"></canvas>
                <div id="orbStatus" style="position: absolute; top: 10px; left: 15px; color: white; font-size: 12px; background: rgba(0,0,0,0.3); padding: 5px 10px; border-radius: 15px;">
                    ‚ö™ Idle
                </div>
                <div id="orbControls" style="position: absolute; bottom: 15px; left: 50%; transform: translateX(-50%); display: flex; gap: 10px;">
                    <button id="startCall" onclick="startWebCall()" style="background: #28a745; color: white; border: none; padding: 10px 20px; border-radius: 25px; cursor: pointer; font-size: 16px;">üìû Start Call</button>
                    <button id="endCall" onclick="endWebCall()" style="background: #dc3545; color: white; border: none; padding: 10px 20px; border-radius: 25px; cursor: pointer; font-size: 16px; display: none;">üìû End Call</button>
                </div>
            </div>

            <!-- Conversation Log -->
            <div id="conversationLog" style="max-height: 200px; overflow-y: auto; background: #f8f9fa; border-radius: 8px; padding: 15px; margin: 15px 0; border: 1px solid #e9ecef;">
                <div style="text-align: center; color: #6c757d; font-style: italic;">Conversation will appear here...</div>
            </div>

            <button type="button" onclick="hideVoiceTestPanel()" style="background-color: #6c757d;">Close</button>
        </div>

        <div id="responseArea" class="response-area" style="display: none;">
            <h3>Response:</h3>
            <pre id="responseContent"></pre>
        </div>
    </div>

    <script src="https://js.puter.com/v2/"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://unpkg.com/@vapi-ai/web@latest/dist/index.js"></script>
    <script>
        async function sendRequest() {
            const apiKey = document.getElementById('apiKey').value;
            const endpoint = document.getElementById('endpoint').value;
            const customEndpoint = document.getElementById('customEndpoint').value;
            const requestBody = document.getElementById('requestBody').value;
            
            if (!apiKey) {
                showResponse('Please enter your API key', 'error');
                return;
            }

            let finalEndpoint = endpoint === '/webhook/custom' ? customEndpoint : endpoint;
            if (!finalEndpoint) {
                showResponse('Please specify an endpoint', 'error');
                return;
            }

            let parsedBody;
            try {
                parsedBody = requestBody ? JSON.parse(requestBody) : {};
            } catch (e) {
                showResponse('Invalid JSON in request body: ' + e.message, 'error');
                return;
            }

            showResponse('Sending request...', 'loading');

            const url = 'https://api.vapi.ai' + finalEndpoint;
            
            try {
                // Use Puter.js for CORS-free requests
                const response = await puter.net.fetch(url, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': 'Bearer ' + apiKey
                    },
                    body: JSON.stringify(parsedBody)
                });

                const responseText = await response.text();
                let responseData;
                
                try {
                    responseData = JSON.parse(responseText);
                } catch (e) {
                    responseData = responseText;
                }

                const result = {
                    status: response.status,
                    statusText: response.statusText,
                    headers: Object.fromEntries(response.headers.entries()),
                    data: responseData
                };

                const className = response.ok ? 'success' : 'error';
                
                // Highlight assistant ID if created successfully
                let displayContent = JSON.stringify(result, null, 2);
                if (response.ok && responseData && responseData.id && finalEndpoint === '/assistant') {
                    displayContent = `üéâ ASSISTANT CREATED SUCCESSFULLY!\n\nüìã Assistant ID: ${responseData.id}\nüìù Name: ${responseData.name || 'Unnamed Assistant'}\n\n` + displayContent;
                }
                
                showResponse(displayContent, className);
            } catch (error) {
                showResponse('Request failed: ' + error.message, 'error');
            }
        }

        function showResponse(content, className) {
            const responseArea = document.getElementById('responseArea');
            const responseContent = document.getElementById('responseContent');
            
            responseContent.textContent = content;
            responseContent.className = className;
            responseArea.style.display = 'block';
            
            responseArea.scrollIntoView({ behavior: 'smooth' });
        }

        function validateJSON() {
            const requestBody = document.getElementById('requestBody').value;
            
            if (!requestBody.trim()) {
                showResponse('No JSON to validate', 'error');
                return;
            }

            try {
                const parsed = JSON.parse(requestBody);
                showResponse('Valid JSON:\n' + JSON.stringify(parsed, null, 2), 'success');
            } catch (e) {
                showResponse('Invalid JSON: ' + e.message, 'error');
            }
        }

        function loadCreateCallPreset() {
            document.getElementById('endpoint').value = '/call';
            document.getElementById('requestBody').value = JSON.stringify({
                "assistantId": "b7bec22e-3e31-4977-af23-583902dc95e9",
                "phoneNumberId": "68d5ed76-510d-472f-8441-1cdb3cd1b37a",
                "customer": {
                    "number": "+13057768712"
                }
            }, null, 2);
        }

        function loadCreateAssistantPreset() {
            document.getElementById('endpoint').value = '/assistant';
            document.getElementById('requestBody').value = JSON.stringify({
                "name": "Kokoro Voice Assistant",
                "model": {
                    "provider": "groq",
                    "model": "llama-3.3-70b-versatile",
                    "messages": [
                        {
                            "role": "system",
                            "content": "You are a helpful AI voice assistant powered by Kokoro TTS. Keep responses conversational, concise, and natural for voice interaction. Speak in a friendly, professional tone."
                        }
                    ]
                },
                "voice": {
                    "provider": "custom-voice",
                    "server": {
                        "url": "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                        "secret": "edge-tts-fallback",
                        "timeoutSeconds": 60,
                        "headers": {
                            "Content-Type": "application/json",
                            "X-Client-ID": "vapi-kokoro-default"
                        }
                    },
                    "fallbackPlan": {
                        "voices": [
                            {
                                "provider": "custom-voice",
                                "server": {
                                    "url": "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                                    "secret": "your-webhook-secret",
                                    "timeoutSeconds": 60,
                                    "headers": {
                                        "Content-Type": "application/json",
                                        "Authorization": "Bearer 445a1e08-666d-47ea-abdd-cc0ac09d23bc",
                                        "X-Client-ID": "vapi-kokoro-default"
                                    }
                                }
                            }
                        ]
                    }
                },
                "firstMessage": "Hello! I'm your Kokoro voice assistant. How can I help you today?",
                "recordingEnabled": true,
                "endCallFunctionEnabled": true,
                "silenceTimeoutSeconds": 30,
                "maxDurationSeconds": 600,
                "backgroundSound": "office",
                "backchannelingEnabled": true,
                "backgroundDenoisingEnabled": true
            }, null, 2);
        }

        function loadWebhookPreset() {
            document.getElementById('endpoint').value = '/webhook/custom';
            document.getElementById('customEndpoint').value = '/webhook/endpoint';
            document.getElementById('requestBody').value = JSON.stringify({
                "event": "call.ended",
                "data": {
                    "callId": "call-123",
                    "duration": 120
                }
            }, null, 2);
        }

        function loadCustomTTSPreset() {
            document.getElementById('endpoint').value = '/assistant';
            document.getElementById('requestBody').value = JSON.stringify({
                "name": "Kokoro TTS Assistant",
                "model": {
                    "provider": "groq",
                    "model": "llama-3.3-70b-versatile",
                    "messages": [
                        {
                            "role": "system",
                            "content": "You are a helpful voice assistant. Keep responses concise and conversational."
                        }
                    ]
                },
                "voice": {
                    "provider": "custom-voice",
                    "server": {
                        "url": "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                        "secret": "your-webhook-secret",
                        "timeoutSeconds": 60,
                        "headers": {
                            "Content-Type": "application/json",
                            "Authorization": "Bearer 445a1e08-666d-47ea-abdd-cc0ac09d23bc",
                            "X-Client-ID": "vapi-kokoro-integration"
                        }
                    },
                    "fallbackPlan": {
                        "voices": [
                            {
                                "provider": "custom-voice",
                                "server": {
                                    "url": "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                                    "secret": "edge-tts-fallback"
                                }
                            }
                        ]
                    }
                },
                "firstMessage": "Hello! I'm your Kokoro TTS voice assistant. How can I help you today?",
                "recordingEnabled": true,
                "endCallFunctionEnabled": true
            }, null, 2);
        }

        function loadEdgeTTSPreset() {
            document.getElementById('endpoint').value = '/assistant';
            document.getElementById('requestBody').value = JSON.stringify({
                "name": "Edge TTS Assistant",
                "model": {
                    "provider": "groq",
                    "model": "llama-3.3-70b-versatile",
                    "messages": [
                        {
                            "role": "system",
                            "content": "You are a helpful voice assistant powered by Microsoft Edge TTS. Keep responses concise and conversational."
                        }
                    ]
                },
                "voice": {
                    "provider": "custom-voice",
                    "server": {
                        "url": "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                        "secret": "edge-tts-fallback",
                        "timeoutSeconds": 30,
                        "headers": {
                            "Content-Type": "application/json",
                            "X-Client-ID": "vapi-edge-tts-integration"
                        }
                    },
                    "fallbackPlan": {
                        "voices": [
                            {
                                "provider": "custom-voice",
                                "server": {
                                    "url": "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                                    "secret": "your-webhook-secret",
                                    "timeoutSeconds": 60,
                                    "headers": {
                                        "Content-Type": "application/json",
                                        "Authorization": "Bearer 445a1e08-666d-47ea-abdd-cc0ac09d23bc",
                                        "X-Client-ID": "vapi-kokoro-fallback"
                                    }
                                }
                            }
                        ]
                    }
                },
                "firstMessage": "Hello! I'm your Edge TTS voice assistant. How can I help you today?",
                "recordingEnabled": true,
                "endCallFunctionEnabled": true
            }, null, 2);
        }

        function clearForm() {
            document.getElementById('requestBody').value = '';
            document.getElementById('customEndpoint').value = '';
            document.getElementById('responseArea').style.display = 'none';
        }

        // Show/hide custom endpoint field based on selection
        document.getElementById('endpoint').addEventListener('change', function() {
            const customField = document.getElementById('customEndpoint').parentElement;
            customField.style.display = this.value === '/webhook/custom' ? 'block' : 'none';
        });

        // VAPI Web Calling Integration
        let vapi = null;
        let activeCall = null;
        
        // AI Orb Chat functions
        let scene, camera, renderer, orb, orbMaterial;
        let isConversationActive = false;
        let animationId = null;

        function showVoiceTestPanel() {
            document.getElementById('voiceTestPanel').style.display = 'block';
            document.getElementById('responseArea').style.display = 'none';
            updateVoiceOptions();
            initializeOrb();
            document.getElementById('voiceTestPanel').scrollIntoView({ behavior: 'smooth' });
        }

        function hideVoiceTestPanel() {
            document.getElementById('voiceTestPanel').style.display = 'none';
            if (animationId) {
                cancelAnimationFrame(animationId);
            }
            if (renderer) {
                renderer.dispose();
            }
        }

        function updateVoiceOptions() {
            const provider = document.getElementById('voiceProvider').value;
            const voiceSelect = document.getElementById('voiceSelect');
            
            voiceSelect.innerHTML = '';
            
            if (provider === 'kokoro') {
                const kokoroVoices = [
                    'af_heart', 'af_nova', 'am_adam', 'am_michael', 'bm_lewis'
                ];
                kokoroVoices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice;
                    option.textContent = `Kokoro - ${voice}`;
                    voiceSelect.appendChild(option);
                });
            } else if (provider === 'edge') {
                const edgeVoices = [
                    'en-US-AriaNeural', 'en-US-JennyNeural', 'en-US-GuyNeural',
                    'en-US-SaraNeural', 'en-US-TonyNeural', 'en-US-NancyNeural',
                    'en-GB-LibbyNeural', 'en-GB-RyanNeural', 'en-AU-NatashaNeural',
                    'en-CA-ClaraNeural', 'en-IN-NeerjaNeural'
                ];
                edgeVoices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice;
                    option.textContent = `Edge - ${voice}`;
                    voiceSelect.appendChild(option);
                });
            }
        }

        function initializeOrb() {
            console.log('Initializing orb...');
            const canvas = document.getElementById('orbCanvas');
            const container = document.getElementById('orbContainer');
            
            if (!canvas || !container) {
                console.error('Canvas or container not found');
                return;
            }
            
            if (!THREE) {
                console.error('Three.js not loaded');
                return;
            }
            
            // Scene setup
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, container.offsetWidth / container.offsetHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true, antialias: true });
            renderer.setSize(container.offsetWidth, container.offsetHeight);
            renderer.setClearColor(0x000000, 0);
            
            console.log('Three.js setup complete');

            // Create orb geometry
            const geometry = new THREE.IcosahedronGeometry(1.5, 4);
            
            // Custom shader material
            orbMaterial = new THREE.ShaderMaterial({
                uniforms: {
                    time: { value: 0.0 },
                    speaking: { value: 0.0 },
                    listening: { value: 0.0 },
                    colorR: { value: 0.3 },
                    colorG: { value: 0.6 },
                    colorB: { value: 1.0 }
                },
                vertexShader: `
                    uniform float time;
                    uniform float speaking;
                    uniform float listening;
                    varying vec3 vNormal;
                    varying vec3 vPosition;
                    
                    // Simple noise function
                    float noise(vec3 pos) {
                        return sin(pos.x * 10.0 + time) * sin(pos.y * 10.0 + time) * sin(pos.z * 10.0 + time) * 0.1;
                    }
                    
                    void main() {
                        vNormal = normalize(normalMatrix * normal);
                        vPosition = position;
                        
                        vec3 pos = position;
                        float displacement = noise(pos) * (speaking * 0.3 + listening * 0.1);
                        pos += normal * displacement;
                        
                        gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
                    }
                `,
                fragmentShader: `
                    uniform float time;
                    uniform float speaking;
                    uniform float listening;
                    uniform float colorR;
                    uniform float colorG;
                    uniform float colorB;
                    varying vec3 vNormal;
                    varying vec3 vPosition;
                    
                    void main() {
                        float intensity = pow(0.7 - dot(vNormal, vec3(0.0, 0.0, 1.0)), 2.0);
                        
                        vec3 baseColor = vec3(colorR, colorG, colorB);
                        vec3 speakingColor = vec3(1.0, 0.5, 0.2);
                        vec3 listeningColor = vec3(0.2, 1.0, 0.5);
                        
                        vec3 finalColor = baseColor;
                        finalColor = mix(finalColor, speakingColor, speaking);
                        finalColor = mix(finalColor, listeningColor, listening);
                        
                        float pulse = sin(time * 5.0) * 0.1 + 0.9;
                        finalColor *= pulse;
                        
                        gl_FragColor = vec4(finalColor * intensity, 1.0);
                    }
                `,
                transparent: true,
                side: THREE.DoubleSide
            });

            orb = new THREE.Mesh(geometry, orbMaterial);
            scene.add(orb);

            camera.position.z = 4;

            animate();
        }

        function animate() {
            animationId = requestAnimationFrame(animate);
            
            if (orbMaterial) {
                orbMaterial.uniforms.time.value += 0.01;
                
                // Auto-rotate orb
                orb.rotation.x += 0.005;
                orb.rotation.y += 0.01;
            }
            
            renderer.render(scene, camera);
        }

        function updateOrbStatus(status, color = '#ffffff') {
            const statusDiv = document.getElementById('orbStatus');
            statusDiv.textContent = status;
            statusDiv.style.color = color;
        }

        function addConversationMessage(type, text) {
            const log = document.getElementById('conversationLog');
            const time = new Date().toLocaleTimeString();
            const icon = type === 'user' ? 'üé§' : 'ü§ñ';
            const className = type === 'user' ? 'user-message' : 'ai-message';
            
            if (log.innerHTML.includes('Conversation will appear here')) {
                log.innerHTML = '';
            }
            
            log.innerHTML += `
                <div class="${className}" style="margin: 8px 0; padding: 8px; border-radius: 8px; background: ${type === 'user' ? '#e3f2fd' : '#f3e5f5'};">
                    <strong>${icon} ${type === 'user' ? 'You' : 'AI'}</strong> <small style="color: #666;">${time}</small><br>
                    ${text}
                </div>
            `;
            log.scrollTop = log.scrollHeight;
        }

        async function startWebCall() {
            console.log('Starting VAPI web call...');
            if (isConversationActive) return;
            
            try {
                // Initialize VAPI if not already done
                if (!vapi) {
                    vapi = new Vapi('445a1e08-666d-47ea-abdd-cc0ac09d23bc');
                }
                
                isConversationActive = true;
                updateOrbStatus('üü¢ Connecting...', '#ffaa00');
                
                document.getElementById('startCall').style.display = 'none';
                document.getElementById('endCall').style.display = 'block';
                
                // Clear conversation log
                document.getElementById('conversationLog').innerHTML = '';
                addConversationMessage('system', 'Connecting to voice assistant...');
                
                // Start VAPI call with proper assistant configuration
                activeCall = await vapi.start({
                    assistant: {
                        model: {
                            provider: "openai",
                            model: "gpt-4",
                            messages: [
                                {
                                    role: "system",
                                    content: "You are a helpful voice assistant. Keep responses concise and conversational. Maximum 2-3 sentences per response."
                                }
                            ]
                        },
                        voice: {
                            provider: "custom-voice",
                            server: {
                                url: "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                                secret: "your-webhook-secret",
                                timeoutSeconds: 60,
                                headers: {
                                    "Content-Type": "application/json",
                                    "X-Client-ID": "vapi-web-calling"
                                }
                            },
                            fallbackPlan: {
                                voices: [
                                    {
                                        provider: "custom-voice",
                                        server: {
                                            url: "https://5570b7b65efe.ngrok-free.app/api/synthesize",
                                            secret: "your-webhook-secret"
                                        }
                                    }
                                ]
                            }
                        },
                        firstMessage: "Hello! I'm your voice assistant. How can I help you today?",
                        recordingEnabled: true,
                        endCallFunctionEnabled: true,
                        silenceTimeoutSeconds: 30,
                        maxDurationSeconds: 600
                    }
                });
                
                console.log('VAPI call started:', activeCall);
                updateOrbStatus('üü¢ Connected! Listening...', '#00ff00');
                
                // Set orb to listening state
                if (orbMaterial) {
                    orbMaterial.uniforms.listening.value = 1.0;
                    console.log('Orb set to listening state');
                }
                
                addConversationMessage('system', 'Voice assistant connected! Start speaking...');
                
                // Set up call event listeners
                setupCallEventListeners();
                
            } catch (error) {
                console.error('Failed to start VAPI call:', error);
                updateOrbStatus('‚ùå Call Failed', '#ff0000');
                addConversationMessage('error', 'Failed to connect: ' + error.message);
                
                // Reset UI
                isConversationActive = false;
                document.getElementById('startCall').style.display = 'block';
                document.getElementById('endCall').style.display = 'none';
            }
        }

        async function endWebCall() {
            console.log('Ending VAPI web call...');
            
            try {
                if (activeCall && vapi) {
                    await vapi.stop();
                    console.log('VAPI call ended');
                }
            } catch (error) {
                console.error('Error ending call:', error);
            }
            
            // Reset state
            isConversationActive = false;
            activeCall = null;
            updateOrbStatus('‚ö™ Idle');
            
            document.getElementById('startCall').style.display = 'block';
            document.getElementById('endCall').style.display = 'none';
            
            if (orbMaterial) {
                orbMaterial.uniforms.listening.value = 0.0;
                orbMaterial.uniforms.speaking.value = 0.0;
            }
            
            addConversationMessage('system', 'Call ended');
        }
        
        function setupCallEventListeners() {
            if (!vapi) return;
            
            vapi.on('call-start', () => {
                console.log('Call started');
                updateOrbStatus('üü¢ Call Active', '#00ff00');
                addConversationMessage('system', 'Call started successfully!');
            });
            
            vapi.on('call-end', () => {
                console.log('Call ended');
                endWebCall();
            });
            
            vapi.on('speech-start', () => {
                console.log('User started speaking');
                updateOrbStatus('üé§ Listening...', '#00ff00');
                if (orbMaterial) {
                    orbMaterial.uniforms.listening.value = 1.0;
                    orbMaterial.uniforms.speaking.value = 0.0;
                }
            });
            
            vapi.on('speech-end', () => {
                console.log('User stopped speaking');
                updateOrbStatus('üß† Thinking...', '#ffaa00');
                if (orbMaterial) {
                    orbMaterial.uniforms.listening.value = 0.0;
                }
            });
            
            vapi.on('message', (message) => {
                console.log('Message received:', message);
                if (message.type === 'transcript' && message.transcriptType === 'final') {
                    addConversationMessage('user', message.transcript);
                } else if (message.type === 'conversation-update') {
                    if (message.conversation && message.conversation.length > 0) {
                        const lastMessage = message.conversation[message.conversation.length - 1];
                        if (lastMessage.role === 'assistant') {
                            addConversationMessage('ai', lastMessage.content);
                        }
                    }
                }
            });
            
            vapi.on('error', (error) => {
                console.error('VAPI error:', error);
                updateOrbStatus('‚ùå Error', '#ff0000');
                addConversationMessage('error', 'Call error: ' + error.message);
            });
        }

        // Legacy function - keeping for compatibility but not used in web calling
        async function simulateUserInput(text) {
            console.log('simulateUserInput called but not used in web calling mode');
        }

        // Conversation history - now managed by VAPI
        // Legacy variable kept for compatibility

        // Legacy function - now handled by VAPI Web SDK
        async function generateAIResponse(userText) {
            console.log('generateAIResponse: Now handled by VAPI Web SDK');
        }

        // Legacy function - conversation flow now handled by VAPI
        async function generateFollowUpQuestion(previousResponse) {
            console.log('generateFollowUpQuestion: Now handled by VAPI Web SDK');
        }

        // Legacy function - TTS now handled by VAPI via webhook
        async function testVoiceSynthesis(text) {
            console.log('testVoiceSynthesis: Now handled by VAPI webhook to TTS server');
        }

        // Initial setup
        document.getElementById('customEndpoint').parentElement.style.display = 'none';
    </script>
</body>
</html>